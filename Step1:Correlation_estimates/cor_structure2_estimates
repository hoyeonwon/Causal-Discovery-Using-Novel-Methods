library(psych)

set.seed(123)

# Number of iterations
n_iterations <- 100
n_obs_values <- c(50, 100, 200, 400)
coeff <- runif(1, 0.8, 0.9)
n_variables <- 10

# Define true structure to compare with
true_structure_two <- matrix(0, nrow = n_variables, ncol = n_variables)

# Define the edges in the graph
edges_two <- c("AB", "AC", "BD", "BE", "EG", "EF", "DG", "EG", "GH", "GI", "HJ")

# Populate the adjacency matrix
for (edge_two in edges_two) {
  from <- substr(edge_two, 1, 1) # Extract the source node
  to <- substr(edge_two, 2, 2)   # Extract the destination node
  true_structure_two[match(from, LETTERS), match(to, LETTERS)] <- 1
}

# Print the adjacency matrix (True Structure)
rownames(true_structure_two) <- colnames(true_structure_two) <- c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")

results <- list()

for (n_obs in n_obs_values) {
  avg_FP <- matrix(0, nrow = n_variables, ncol = n_variables)
  avg_FN <- matrix(0, nrow = n_variables, ncol = n_variables)
  avg_TP <- matrix(0, nrow = n_variables, ncol = n_variables)
  avg_TN <- matrix(0, nrow = n_variables, ncol = n_variables)

  for (iteration in 1:n_iterations) {

    # Step 1: Generate a random true structure (adjacency matrix)
    a = rnorm(100, mean = 0, sd = 1)
    b = coeff * a + rnorm(100, 0, 1)
    c = coeff * a + rnorm(100, 0, 1)
    d = coeff * b + rnorm(100, 0, 1)
    e = coeff * b + rnorm(100, 0, 1)
    f = coeff * e + rnorm(100, 0, 1)
    g = coeff * d + coeff * e + rnorm(100, 0, 1)
    h = coeff * g + rnorm(100, 0, 1)
    i = coeff * g + rnorm(100, 0, 1)
    j = coeff * h + rnorm(100, 0, 1)

    # Combine variables into a matrix
    sim_data <- cbind(a, b, c, d, e, f, g, h, i, j)

    # Step 2: Convert simulated data to correlation matrix
    correlation_matrix <- cor(sim_data, method = "pearson")

    # Step 3: Calculate p-values of correlation matrix using Fisher's Z transformation
    p_val_cor <- cor_to_pval(correlation_matrix, n_obs)
    
    # Step 4: Initialize evaluation matrices
    FP <- matrix(0, nrow = n_variables, ncol = n_variables)
    FN <- matrix(0, nrow = n_variables, ncol = n_variables)
    TP <- matrix(0, nrow = n_variables, ncol = n_variables)
    TN <- matrix(0, nrow = n_variables, ncol = n_variables)

    # Step 5: Calculate Bonferroni corrected threshold
    alpha <- 0.05  # Significance level
    bonferroni_threshold <- alpha / choose(n_variables, 2)

    # Step 6: Count correct/ incorrect nodes based on the true structure
    for (i in 1:n_variables) {
      for (j in 1:n_variables) {
        estimated_value <- p_val_cor[i, j]
        true_value <- true_structure_two[i, j]

        if ((estimated_value <= bonferroni_threshold) && true_value == 1) {
          TP[i, j] <- TP[i, j] + 1
        } else if ((estimated_value <= bonferroni_threshold) && true_value == 0) {
          FP[i, j] <- FP[i, j] + 1
        } else if ((estimated_value > bonferroni_threshold) && true_value == 1) {
          FN[i, j] <- FN[i, j] + 1
        } else if ((estimated_value > bonferroni_threshold) && true_value == 0) {
          TN[i, j] <- TN[i, j] + 1
        }
      }
    }

    # Accumulate evaluation matrices
    avg_FP <- avg_FP + FP
    avg_FN <- avg_FN + FN
    avg_TP <- avg_TP + TP
    avg_TN <- avg_TN + TN
  }

  # Store results
  results[[as.character(n_obs)]] <- list(
    "FP" = avg_FP / n_iterations,
    "FN" = avg_FN / n_iterations,
    "TP" = avg_TP / n_iterations,
    "TN" = avg_TN / n_iterations
  )
}

structuretwo_50 <- reassign_diagonals_to_zeros(results[[as.character(50)]])
structuretwo_100 <- reassign_diagonals_to_zeros(results[[as.character(100)]])
structuretwo_200 <- reassign_diagonals_to_zeros(results[[as.character(200)]])
structuretwo_400 <- reassign_diagonals_to_zeros(results[[as.character(400)]])
